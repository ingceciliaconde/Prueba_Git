{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingceciliaconde/Prueba_Git/blob/master/clase_4_modelos_de_regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aprendizaje Automático** - 2024\n",
        "# Clase 4: Regresión\n",
        "\n",
        "Contenidos:\n",
        "* Introducción a Scikit-Learn\n",
        "* Regresión lineal con Scikit-Learn\n",
        "* Modelos lineales con regularización\n",
        "* Tratamiento de variables categóricas y escalas"
      ],
      "metadata": {
        "id": "pQWH9FBr4Hd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "op_IdCLIcYfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Fuentes:*\n",
        "\n",
        "* https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html\n",
        "* https://inria.github.io/scikit-learn-mooc/python_scripts/02_numerical_pipeline_introduction.html\n",
        "* https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb\n"
      ],
      "metadata": {
        "id": "5IL3zWgJ3qYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción a Scikit-Learn\n",
        "\n",
        "Scikit-learn es una librería de aprendizaje automático de código abierto para el lenguaje de programación Python. Proporciona herramientas simples y eficientes para el análisis de datos y la minería de datos, así como para la construcción de modelos de aprendizaje automático. Scikit-learn es una de las bibliotecas más populares para el aprendizaje automático en Python y se utiliza ampliamente en la industria y la academia. Admite librerías numéricas y científicas de Python como NumPy y SciPy, o Pandas.\n",
        "\n",
        "![fig_sckl](https://ulhpc-tutorials.readthedocs.io/en/latest/python/advanced/scikit-learn/images/scikit.png)\n",
        "*Image Source: ulhpc-tutorials.readthedocs.io*"
      ],
      "metadata": {
        "id": "W8BdLT9KGyKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustar un modelo y hacer predicciones\n",
        "\n",
        "La librería esta compuesta por modulos que nos otorgan distintas herramientas desde `model_selection` que nos brinda herramientas necesarias para la manipular las particiones de los datos o `metrics` para las métricas. Por otro lado tendremos distintos módulos para cada modelo como por ejemplo `neighbors` donde encontraremos modelos que funcionan a partir de distancias como `KNN`\n",
        "\n",
        "Debemos primero importar el modelo e instanciarlo:\n",
        "\n",
        "```\n",
        "from sklearn.MODULO import MODELO\n",
        "\n",
        "% instanciamos el modelo definiendo sus hiperparametros\n",
        "modelo = MODELO()\n",
        "```\n",
        "\n",
        "El método `fit` se llama para entrenar el modelo a partir de los datos de entrada (features o características) y la etiqueta que queremos predecir o el objetivo (target).\n",
        "\n",
        "```\n",
        "modelo.fit(data, target)\n",
        "```\n",
        "\n",
        "El aprendizaje se puede representar de la siguiente manera:\n",
        "\n",
        "![imagen.png](https://inria.github.io/scikit-learn-mooc/_images/api_diagram-predictor.fit.svg)\n",
        "\n",
        "El método fit se compone de dos elementos:\n",
        "- un algoritmo de aprendizaje\n",
        "- algun estado del modelo (los parametros por ejemplo)\n",
        "\n",
        "El algoritmo de aprendizaje toma los datos de entrenamiento y el objetivo de entrenamiento como entrada y establece los estados del modelo. Estos estados del modelo se utilizarán más adelante para predecir (para clasificadores y regresores) o transformar datos (para transformadores).Tanto el algoritmo de aprendizaje como el tipo de estados del modelo son específicos para cada tipo de modelo y a veces podremos modificarlas.\n"
      ],
      "metadata": {
        "id": "TjpQSrRtG6BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usemos nuestro modelo para hacer algunas predicciones utilizando el mismo conjunto de datos y usando el método `predict`.\n",
        "```\n",
        "target_predicted = model.predict(data)\n",
        "```\n",
        "Podemos ilustrar el mecanismo de predicción de la siguiente manera:\n",
        "\n",
        "![](\n",
        "https://inria.github.io/scikit-learn-mooc/_images/api_diagram-predictor.predict.svg)\n",
        "\n",
        "Para predecir, un modelo utiliza una función de predicción que utilizará los datos de entrada junto con los estados del modelo. Al igual que con el algoritmo de aprendizaje y los estados del modelo, la función de predicción es específica para cada tipo de modelo."
      ],
      "metadata": {
        "id": "Wrjg2dsdHALw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion lineal multiple\n"
      ],
      "metadata": {
        "id": "MzZUwFSWi4hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV, ElasticNet, ElasticNetCV\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "yWUkJGRqGixV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referencias / Material suplementario\n",
        "\n",
        "- Cap. 3 Linear Methods for Regressiondel del libro [The Elements of Statistical Learning](https://hastie.su.domains/Papers/ESLII.pdf)\n",
        "\n",
        "- Cap. 6 Linear Model Selection and Regularization del libro [An Introduction to Statistical Learning](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)"
      ],
      "metadata": {
        "id": "LXUJIJBBGkKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo: el dataset de diabetes\n",
        "\n",
        "Vamos a utilizar un conjunto de datos muy popular sobre diabetes. El dataset \"diabetes\" contiene un total de 442 observaciones y 10 variables (características) numéricas. Las variables del dataset \"diabetes\" son las siguientes:\n",
        "\n",
        "    Edad: Edad del paciente en años.\n",
        "    Sexo: Sexo del paciente (0 = Femenino, 1 = Masculino).\n",
        "    Índice de masa corporal (IMC): Medida del peso en relación con la altura del paciente.\n",
        "    Presión arterial media (MAP): Medida de la presión arterial promedio del paciente.\n",
        "    Tasa de s1 de serología del suero: Un indicador del nivel de s1 de serología del suero del paciente.\n",
        "    Tasa de s2 de serología del suero: Un indicador del nivel de s2 de serología del suero del paciente.\n",
        "    Tasa de s3 de serología del suero: Un indicador del nivel de s3 de serología del suero del paciente.\n",
        "    Tasa de s4 de serología del suero: Un indicador del nivel de s4 de serología del suero del paciente.\n",
        "    Tasa de s5 de serología del suero: Un indicador del nivel de s5 de serología del suero del paciente.\n",
        "    Tasa de s6 de serología del suero: Un indicador del nivel de s6 de serología del suero del paciente.\n",
        "\n",
        "El target o variable de salida en el dataset es la *progresión de la diabetes* en un año. Esta variable representa la medida de la progresión de la enfermedad en un año para cada paciente en el estudio. Es un valor numérico continuo que indica la magnitud de la progresión de la diabetes en un año, y se utiliza como la variable objetivo en los modelos de regresión construidos con este dataset."
      ],
      "metadata": {
        "id": "XrmxBrNcbrj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_data = load_diabetes()\n",
        "diabetes = pd.DataFrame(diabetes_data['data'], columns=diabetes_data['feature_names'])\n",
        "diabetes['target'] = diabetes_data['target']\n",
        "\n",
        "# Visualización de algunas variables utilizando Seaborn\n",
        "sns.set(style='ticks')\n",
        "sns.pairplot(diabetes, x_vars=['age', 'bmi', 'bp', 's1', 's2'], y_vars='target', kind='scatter')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LEbAy51Ti-Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Ejercicio 1\n",
        "\n",
        "Observe la distribución de las features, ¿nota algo en particular? ¿Qué tan correlacionadas estan los features? Realizar gráficos para analizar estas preguntas."
      ],
      "metadata": {
        "id": "2UqWTQYnoST6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR"
      ],
      "metadata": {
        "id": "18XP81Ah7JHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WTJzILJ7a4IV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamos un modelo lineal: split\n",
        "Para el desarrollo de nuestro modelo vamos a necesitar realizar una separación de datos, para eso usaremos un split de `train`, `val` y `test`. **El test no lo utilizaremos hasta tener el mejor de todos los modelos**:\n",
        "\n",
        "![image.png](https://cdn.shortpixel.ai/spai/q_lossy+w_730+to_webp+ret_img/https://algotrading101.com/learn/wp-content/uploads/2020/06/training-validation-test-data-set.png)\n",
        "\n",
        "Creemos nuestra matriz de features `X` y nuestro vector de targets `y`."
      ],
      "metadata": {
        "id": "3GTnvzyK7Rar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetes.drop('target', axis=1)\n",
        "y = diabetes['target']"
      ],
      "metadata": {
        "id": "AuzJVyt64vUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ejercicio 2\n",
        "\n",
        "Utilizar la función [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para crear los tres conjuntos pedidos, utilizar el 70% para train, 15% para validation y 15% para test. Fijar la semilla aleatoria en 20."
      ],
      "metadata": {
        "id": "erc5yk5-30eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separación del dataset en train, dev y test\n",
        "# COMPLETAR\n",
        "seed = 20\n",
        "np.random.seed(seed)\n",
        "# X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "metadata": {
        "id": "CQMahWrabrQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo quedaron las relaciones finales de train, validation y test?"
      ],
      "metadata": {
        "id": "nQ0D3cHoaZ_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
        "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
        "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
      ],
      "metadata": {
        "id": "I2ZLWPfiblnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciemos nuestro primer modelo [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), entrenémoslo y evaluémoslo en el conjunto de validación:"
      ],
      "metadata": {
        "id": "Db21FKji5UKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación y entrenamiento del modelo de regresión lineal\n",
        "reg_linear = LinearRegression()\n",
        "reg_linear.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones en el conjunto de validación\n",
        "y_val_pred_clasica = reg_linear.predict(X_val)\n",
        "\n",
        "# Cálculo del error cuadrático medio en el conjunto de validación\n",
        "mse_clasica = mean_squared_error(y_val, y_val_pred_clasica)\n",
        "\n",
        "print(\"Error cuadrático medio (Clásica):\", mse_clasica)"
      ],
      "metadata": {
        "id": "uayoQkBRn_bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretación de los $\\beta$\n",
        "Si tenemos en general a los **features normalizados** con media 0 y varianza 1, y son independientes entre si (o en su defecto poco correlacionados), los $\\beta$ **se pueden interpretar de alguna manera como un proxy de importancia** y entender el aporte de las variables al target. Esto quiere decir que el valor del coeficiente me dice cuanto aporta la variación en el feature correspondiente al cambio en el target. Por ejemplo, si el coeficiente $\\beta_j$ es negativo, aumentar el feature $x_j$ correspondiente impacta disminuyendo el valor del target."
      ],
      "metadata": {
        "id": "EGBTvmna1x9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### Ejercicio 3\n",
        "\n",
        "Ver como acceder a los valores de los coeficientes de la regresión lineal, ¿que variable parece ser las importante? Ordenarlas por valor absoluto y mostrarlas en un `barplot`."
      ],
      "metadata": {
        "id": "ohPFRE57a8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "reg_linear"
      ],
      "metadata": {
        "id": "_B00KLIypaiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "e4U5KWtkbEH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión lineal con regularización"
      ],
      "metadata": {
        "id": "-F8NI2RGZTw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las formas estandar de regularizar un modelo es mediante la penalizacion de los valores de los parametros de nuestro modelo. En regresion lineal existen dos maneras muy usuales de hacer: penalización **Ridge** o **Lasso**. La principal diferencia entre estas técnicas es cómo tratan los coeficientes del modelo. *Ridge tiende a reducir todos los coeficientes*, mientras que *Lasso tiene el efecto de reducir algunos coeficientes a cero*, eliminando así algunos predictores del modelo.\n",
        "\n",
        "Estos metodos introducen un nuevo hiperparámetro (en general representados con la letra $\\lambda$ o en el caso de regresion lineal se suele utilizar $\\alpha$) que modula que tanto queremos penalizar el modelo. **Valores altos de este hiperparámetro penalizaran fuertemente el modelo tendiendo a reducir fuertemente la varianza del modelo.** De esta manera, cuando le imponemos penalizaciones al modelo lo volvemos **menos flexible**, es decir, menos suceptible a acomodarse más a los datos en los que se ajusta. Esto hace que el modelo sea menos sensible al ruido de los datos y a los valores particulares usados para su entrenamiento, haciendo que se **reduzca la posibilidad de sobreajuste** a esos datos, y logrando un mejor balance de la varianza que podría hacer que el modelo **generalice mejor** a datos nuevos."
      ],
      "metadata": {
        "id": "mV2x-6grgmY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularización Ridge ($L^2$)\n",
        "\n",
        "La penalización utilizada por el modelo Ridge queda de la siguiente manera:\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal L(\\beta, \\alpha) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij})) ^2 + \\alpha \\sum_{j=1}^{p} {\\beta_j}^2\n",
        "\\end{equation}\n",
        "\n",
        "donde:\n",
        "\n",
        "- $y$ es la variable de respuesta\n",
        "- $\\beta_0$ es el intercept\n",
        "- $x_j$ es la $j$-ésima variable predictora/feature\n",
        "- $\\beta_j$ es el coeficiente correspondiente a la $j$-ésima variable predictora\n",
        "- $\\alpha$ es el **hiperparámetro** de regularización que controla la fuerza de la penalización de la magnitud de los coeficientes.\n",
        "\n",
        "*Nota*: La última parte de la ecuación, $\\sum_{j=1}^{p} \\beta_j^2$, es la función de penalización $L^2$ regulada por $\\alpha>0$ que penaliza más fuertemente a los coeficientes más grandes."
      ],
      "metadata": {
        "id": "DE3nhvd2gVbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4.1\n",
        "\n",
        "Instanciar una [Regresion Lineal Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) con un valor de regularización igual a 0.1, entrenarlo y reportar el error cuadrático medio en el conjunto de validación."
      ],
      "metadata": {
        "id": "tuiB7if1av6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "\n",
        "mse_ridge = ...\n",
        "\n",
        "print(\"Error cuadrático medio (Ridge):\", mse_ridge)"
      ],
      "metadata": {
        "id": "wK4Uozggavs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularización Lasso ($L^1$)\n",
        "\n",
        "La penalización utilizada por el modelo Lasso queda de la siguiente manera:\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal L(\\beta, \\alpha) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij})) ^2 + \\alpha \\sum_{j=1}^{p} |\\beta_j|\n",
        "\\end{equation}\n",
        "\n",
        "*Nota*: La última parte de la ecuación, $\\sum_{j=1}^{p} |\\beta_j|$, es la función de penalización $L^1$ regulada por $\\alpha>0$ que obliga a algunos coeficientes a ser exactamente cero, lo que conduce a una selección de features integrada."
      ],
      "metadata": {
        "id": "Gn11oxOUbBa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4.2\n",
        "\n",
        "Instanciar una [Regresion Lineal Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) con un valor de regularización igual a 0.1, entrenarlo y reportar el error cuadrático medio en el conjunto de validación. ¿Obtuvieron los mismo resultados? ¿Lasso eliminó alguna features ($\\beta=0$)?"
      ],
      "metadata": {
        "id": "aweyeS8AbgRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "mse_lasso = ...\n",
        "\n",
        "print(\"Error cuadrático medio (Lasso):\", mse_lasso)"
      ],
      "metadata": {
        "id": "xqen1NjjcCVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparemos los resultados obtenidos hasta aca en val\n",
        "print(\"Error cuadrático medio (Lasso):\", mse_lasso)\n",
        "print(\"Error cuadrático medio (Ridge):\", mse_ridge)\n",
        "print(\"Error cuadrático medio (Clásica):\", mse_clasica)"
      ],
      "metadata": {
        "id": "GRWuqiuQz7w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Efecto del $\\alpha$\n",
        "\n",
        "Queremos entender como afecta el hiperparámetro de regularización a los valores de los **parámetros** a medida que aumentamos el $\\alpha$ para cada tipo de regularización vista."
      ],
      "metadata": {
        "id": "DpMQ5YLkgdWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 5\n",
        "\n",
        "Grafiquen en dos plots separados los coeficientes (betas) para los modelos de regresión Ridge y Lasso, variando el parámetro de regularización alpha en un rango logarítmico entre 3 y -3 con 100 puntos. Los gráficos deben mostrar cómo los coeficientes de las características cambian en función de alpha para ambos modelos.\n",
        "\n",
        "¿Qué conclusiones pueden sacar? ¿Qué observa? Relacionelo con el dilema sesgo-varianza y el rol de la regularización en ese trade-off, ¿que sucede con alfas muy altos y que sucede con alfas muy bajos?"
      ],
      "metadata": {
        "id": "gACoilryPyMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETAR\n",
        "\n",
        "alphas = ...\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Fittear en entrenamiento un modelo Lasso y un modelo Rigde, graficar los coeficientes (betas)\n",
        "for alpha in alphas:\n",
        "    pass # COMPLETAR\n",
        "\n",
        "# Personalizar y mostrar gráficos\n",
        "axes[0].set_xscale('log')\n",
        "axes[0].set_xlabel('Alfa (Ridge)')\n",
        "axes[0].set_ylabel('Valor del Coeficiente')\n",
        "axes[0].set_title('Coeficientes Ridge')\n",
        "axes[1].set_xscale('log')\n",
        "axes[1].set_xlabel('Alfa (Lasso)')\n",
        "axes[1].set_ylabel('Valor del Coeficiente')\n",
        "axes[1].set_title('Coeficientes Lasso')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "17Dros3iPw2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eligiendo $\\alpha$ con Cross Validation\n",
        "\n",
        "Scikit-learn nos permite elegir el valor de alfa para Ridge y Lasso utilizando cross-validation con los metodos: [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) y [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Estos metodos lo que hacen es dado un conjunto de alfas y una cantidad de folds (ver documentacion parametro `cv`) elegir el mejor de los alfas y con dicho alfa ajustar el modelo de nuevo a todos los datos. Veamoslo con un ejemplo:\n",
        "\n"
      ],
      "metadata": {
        "id": "1fLpUAYDzuLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = np.logspace(-10, 3, 100)\n",
        "\n",
        "reg_ridgeCV = RidgeCV(alphas=alphas, cv=5)\n",
        "reg_lassoCV = LassoCV(alphas=alphas, cv=5)\n",
        "\n",
        "reg_ridgeCV.fit(X_train, y_train);\n",
        "reg_lassoCV.fit(X_train, y_train);"
      ],
      "metadata": {
        "id": "MC6G_YL6CbsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones en el conjunto de validación para Lasso\n",
        "y_val_pred_ridgeCV = reg_ridgeCV.predict(X_val)\n",
        "\n",
        "# Cálculo del error cuadrático medio en el conjunto de validación\n",
        "mse_ridgeCV = mean_squared_error(y_val, y_val_pred_ridgeCV)\n",
        "\n",
        "print(\"Mejor alfa encontrado:\", reg_ridgeCV.alpha_)\n",
        "print(\"Error cuadrático medio (RidgeCV):\", mse_ridgeCV)"
      ],
      "metadata": {
        "id": "jLm8QNTNW8Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones en el conjunto de validación para Lasso\n",
        "y_val_pred_lassoCV = reg_lassoCV.predict(X_val)\n",
        "\n",
        "# Cálculo del error cuadrático medio en el conjunto de validación\n",
        "mse_lassoCV = mean_squared_error(y_val, y_val_pred_lassoCV)\n",
        "\n",
        "print(\"Mejor alfa encontrado:\", reg_lassoCV.alpha_)\n",
        "print(\"Error cuadrático medio (LassoCV):\", mse_lassoCV)"
      ],
      "metadata": {
        "id": "3EEjeU5TU1HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos visualizar los errores que tuvo en cada fold accediendo al atributo mse_path_\n",
        "# OJO: si quieren graficar el de Ridge en vez de acceder a los alfas mediante MODELO.alphas_, se llaman MODELO.alphas\n",
        "plt.semilogx(reg_lassoCV.alphas_, reg_lassoCV.mse_path_, linestyle=\":\")\n",
        "plt.plot(\n",
        "    reg_lassoCV.alphas_,\n",
        "    reg_lassoCV.mse_path_.mean(axis=-1),\n",
        "    color=\"black\",\n",
        "    label=\"Promedio de los folds\",\n",
        "    linewidth=2,\n",
        ")\n",
        "\n",
        "plt.axvline(reg_lassoCV.alpha_, linestyle=\"--\", color=\"black\", label=\"mejor alfa encontrado\")\n",
        "plt.xlabel(r\"$\\alpha$\")\n",
        "plt.ylabel(\"Mean square error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGxgn2FpX8Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Ejercicio Integrador"
      ],
      "metadata": {
        "id": "aYaZWa3Uy6ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ElasticNet\n",
        "\n",
        "[ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) es un modelo que no veremos en detalle pero lo que hace es combinar los dos tipos de regularización, utilizando un hiperparámetro nuevo $\\rho$ que regula que tanto peso le da a cada una de las regularizaciones.\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal L(\\beta) = \\sum_{i=1}^{n}(y_i - \\beta_0 - \\sum_{j=1}^{p}x_{ij}\\beta_j)^2 + \\alpha(\\rho\\sum_{j=1}^{p}|\\beta_j| + \\frac{1-\\rho}{2}\\sum_{j=1}^{p}\\beta_j^2)\n",
        "\\end{equation}\n"
      ],
      "metadata": {
        "id": "b2thvbkHxqtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Cree una celda de código para ajustar un modelo de Elastic Net utilizando $\\alpha=0.1$ y $\\rho=0.5$ en el conjunto de datos de diabetes siguiendo la partición dada en la notebook, si es necesario recurra a la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html).\n"
      ],
      "metadata": {
        "id": "_2KQwe-BqHNM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldgsYbF5tD8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Elija ambos hiperparámetros de ElasticNet usando Validación Cruzada en el conjunto `X_train`. Defina una grilla para eso que tenga al menos 10 puntos espaciados logaritmicamente para cada hiperparámetro. Utilice la función provista por sklearn: [ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV)\n"
      ],
      "metadata": {
        "id": "TeLkVUejtDWw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Do34f3_tGzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3 - Compare los 4 mejores modelos (Ridge, Lasso, ElasticNet y sin regularizar) en el conjunto de `test`. ¿Cuál fue el mejor modelo? Para el mejor modelo, ¿cuál fue la variable que tiene un mayor efecto positivo en el aumento de la glucosa?"
      ],
      "metadata": {
        "id": "IL5lb-LBtGEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BlH-z0gCqV-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}